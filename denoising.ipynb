{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prologue\n",
    "An attempt at implementing [Denoising Induction Motor Sounds](https://arxiv.org/pdf/2208.04462.pdf) for this use case."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 21:51:03.022391: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-21 21:51:03.902784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, time, random, glob, os, pandas\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pydub\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from pydub import effects\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras import layers, losses\n",
    "\n",
    "import keras.models\n",
    "from keras.losses import mse as kmse\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Add, Multiply, Lambda, UpSampling2D, Dot, Permute, RepeatVector\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Cropping2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from keras.callbacks import LambdaCallback, EarlyStopping, ModelCheckpoint\n",
    "import noising\n",
    "from common import *\n",
    "from common import cal_midpoints, gen_mel_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'samples'\n",
    "files = glob.glob(f'{INPUT_DIR}/*.flac')\n",
    "noising.save_overlaid_dataset(files, 3, 15, 'dataset.json', 'overlaid', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dataset : str = 'dataset.json', \n",
    "                train_ratio : float = 0.8,\n",
    "                batch_size : int = 8, gen_type = 'train', shuffle : bool = True):\n",
    "        self.shuffle = shuffle\n",
    "        self.gen_type = gen_type\n",
    "        self.train_ratio = train_ratio\n",
    "        self.test_ratio = self.train_ratio + (1-train_ratio)/2\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = 0\n",
    "        self.samples_per_file = samples_per_file\n",
    "        self.noise_types = ['white', 'pink', 'blue', 'brown', 'violet']\n",
    "        self.map = json.loads(open(dataset).read())\n",
    "        files = list(self.map.keys())\n",
    "        idx = int(train_ratio*len(files))\n",
    "        test_idx = int(self.test_ratio*len(files))\n",
    "        if gen_type == 'train':\n",
    "            self.files = files[0:idx]\n",
    "        elif gen_type == 'test':\n",
    "            self.files = files[idx:test_idx]\n",
    "        else:\n",
    "            self.files = files[test_idx:]\n",
    "        print(f\"{gen_type} loader created with {len(self.files)} samples\")\n",
    "        \n",
    "        self.len = self.__len__()\n",
    "        if self.gen_type != 'test':\n",
    "            self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the number of batches per epoch'''\n",
    "        return (2*len(self.files)) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle and self.gen_type != 'test' :\n",
    "            random.shuffle(self.files)\n",
    "        self.epoch += 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #! generates self.samples_per_file noisy samples per file, can be of the\n",
    "        #! same kind of noise, or can be of different kinds of noises.\n",
    "        inp = []\n",
    "        out = []\n",
    "        const = int(self.batch_size//self.samples_per_file) #! const files make up a batch\n",
    "        for path in self.files[index*const : (index+1)*const]:\n",
    "            orig_sound = pydub.AudioSegment.from_file(path)\n",
    "            orig_array = orig_sound.get_array_of_samples()\n",
    "            for noisy_path in self.map[path]:\n",
    "                noisy_sound = pydub.AudioSegment.from_file(noisy_path)\n",
    "                noisy_array = noisy_sound.get_array_of_samples()\n",
    "                min_len = min(len(noisy_array), len(orig_array))\n",
    "                inp.append(noisy_array[0:min_len])\n",
    "                out.append(orig_array[:min_len])\n",
    "        inp = np.array(inp)\n",
    "        out = np.array(out)\n",
    "        return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, directory : str = '/home/juggernautjha/Desktop/to_rahul/maruti/data/true_samples', \n",
    "                length : int = 200, train_ratio : float = 0.8,\n",
    "                batch_size : int = 32, gen_type = 'train',\n",
    "                samples_per_file : int = 3, shuffle : bool = True):\n",
    "        self.shuffle = shuffle\n",
    "        self.gen_type = gen_type\n",
    "        self.train_ratio = train_ratio\n",
    "        self.test_ratio = self.train_ratio + (1-train_ratio)/2\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = 0\n",
    "        self.pad_to = length\n",
    "        self.samples_per_file = samples_per_file\n",
    "        self.noise_types = ['white', 'pink', 'blue', 'brown', 'violet']\n",
    "        files = glob.glob(f\"{directory}/*.flac\")\n",
    "        idx = int(train_ratio*len(files))\n",
    "        test_idx = int(self.test_ratio*len(files))\n",
    "        if gen_type == 'train':\n",
    "            self.files = files[0:idx]\n",
    "        elif gen_type == 'test':\n",
    "            self.files = files[idx:test_idx]\n",
    "        else:\n",
    "            self.files = files[test_idx:]\n",
    "        print(f\"{gen_type} loader created with {len(self.files)} samples\")\n",
    "\n",
    "        self.len = self.__len__()\n",
    "        if self.gen_type != 'test':\n",
    "            self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Denotes the number of batches per epoch'''\n",
    "        return (2*len(self.files)) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle and self.gen_type != 'test' :\n",
    "            random.shuffle(self.files)\n",
    "        self.epoch += 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #! generates self.samples_per_file noisy samples per file, can be of the\n",
    "        #! same kind of noise, or can be of different kinds of noises.\n",
    "        inp = []\n",
    "        out = []\n",
    "        const = int(self.batch_size//self.samples_per_file) #! const files make up a batch\n",
    "        for path in self.files[index*const : (index+1)*const]:\n",
    "            colors = random.choices(self.noise_types, k =self.samples_per_file)\n",
    "            for color in colors:\n",
    "                noisy, clear = noising.overlay_noise(path, 15, color, self.pad_to)\n",
    "                inp.append(noisy.get_array_of_samples())\n",
    "                out.append(clear.get_array_of_samples())\n",
    "        inp = np.array(inp)\n",
    "        out = np.array(out)\n",
    "        return inp, out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loader created with 14 samples\n",
      "val loader created with 3 samples\n"
     ]
    }
   ],
   "source": [
    "train_generator = FastGenerator('dataset.json', 50, 0.7)\n",
    "val_generator = FastGenerator('dataset.json', 50, 0.7, gen_type='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6239232"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_generator.__getitem__(1)[0][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL (finally??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoise(Model):\n",
    "  def __init__(self, input_size, batch_size):\n",
    "    super(Denoise, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Input(shape = (input_size, 1), batch_size = batch_size),\n",
    "      layers.Conv1D(128, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1D(32, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1D(16, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1D(8, kernel_size=3, activation='relu', kernel_initializer='he_uniform')\n",
    "      ])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Conv1DTranspose(8, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1DTranspose(16, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1DTranspose(32, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1DTranspose(128, kernel_size=3, activation='relu', kernel_initializer='he_uniform'),\n",
    "      layers.Conv1DTranspose(1, kernel_size=3, activation='relu', kernel_initializer='he_uniform')\n",
    "      ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 22:01:09.194531: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-21 22:01:09.286646: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "denoiser = Denoise(6239232, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser.compile('adam', loss=tf.keras.losses.mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-21 22:01:57.550100: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 74870784 exceeds 10% of free system memory.\n",
      "2023-06-21 22:01:57.560775: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 74870784 exceeds 10% of free system memory.\n",
      "2023-06-21 22:01:57.629623: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 149741568 exceeds 10% of free system memory.\n",
      "2023-06-21 22:01:57.686114: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 19166914560 exceeds 10% of free system memory.\n",
      "2023-06-21 22:01:57.686158: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:629 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[6,1,6239230,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer 'conv1d' (type Conv1D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[6,1,6239230,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2D]\n\nCall arguments received by layer 'conv1d' (type Conv1D):\n  • inputs=tf.Tensor(shape=(6, 6239232, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m denoiser\u001b[39m.\u001b[39;49mfit(train_generator, validation_data\u001b[39m=\u001b[39;49mval_generator)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[32], line 21\u001b[0m, in \u001b[0;36mDenoise.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 21\u001b[0m   encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     22\u001b[0m   decoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(encoded)\n\u001b[1;32m     23\u001b[0m   \u001b[39mreturn\u001b[39;00m decoded\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer 'conv1d' (type Conv1D).\n\n{{function_node __wrapped__Conv2D_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[6,1,6239230,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu [Op:Conv2D]\n\nCall arguments received by layer 'conv1d' (type Conv1D):\n  • inputs=tf.Tensor(shape=(6, 6239232, 1), dtype=float32)"
     ]
    }
   ],
   "source": [
    "denoiser.fit(train_generator, validation_data=val_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
